\documentclass[12pt]{article}
\usepackage[a4paper, hmargin={2.8cm, 2.8cm}, vmargin={2.5cm, 2.5cm}]{geometry}
\usepackage{eso-pic} % \AddToShipoutPicture

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[english]{babel}
\usepackage{cite}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage{mathrsfs}
\usepackage{fullpage}
\usepackage[linkcolor=red]{hyperref}
\usepackage[final]{graphicx}
\usepackage{color}
\usepackage{listings}
\renewcommand*\lstlistingname{Code Block}
\definecolor{bg}{rgb}{0.95,0.95,0.95}

%caption distinct from normal text
\usepackage[hang,small,bf]{caption}
\usepackage{hyperref}

\hypersetup{
    colorlinks,%
    citecolor=black,%
    filecolor=black,%
    linkcolor=black,%
    urlcolor=black
}

\author{
  \texttt{Gruppe: 3D} \\
  \texttt{Mikkel Enevoldsen} \\[.4cm]
  \texttt{Kristian Høi} \\[.4cm]
  \texttt{Dominique Chancelier} \\[.4cm]
  \texttt{Carsten Jensen} \\[.4cm]
  Instruktor: Jesper Lundsgaard
  \vspace{8cm}
}

\title{
  \vspace{3cm}
  \Huge{Opgave 8} \\[.25cm]
  \large{Studie af videnskabelig artikel}
  \vspace{.75cm}
}

\begin{document}

\AddToShipoutPicture*{\put(0,0){\includegraphics*[viewport=0 0 700 600]{includes/ku-farve}}}
\AddToShipoutPicture*{\put(0,602){\includegraphics*[viewport=0 600 700 1600]{includes/ku-farve}}}

%% Change `ku-en` to `nat-en` to use the `Faculty of Science` header
\AddToShipoutPicture*{\put(0,0){\includegraphics*{includes/ku-en}}}

\clearpage\maketitle
\thispagestyle{empty}

\newpage

\thispagestyle{empty}

\newpage
\pagestyle{plain}
\setcounter{page}{1}
\pagenumbering{arabic}

\section*{Resumé}

\noindent Da man gennem tidligere undersøgelser har vist, at en endeløs mængde af testdeltagere ikke vil give en endeløs mængde af unikke resultater, undersøger artiklen hvorvidt det samme gælder for evaluatorer. Til dette valgte man fire testdeltagere, der alle var vante med computeren men ikke med programmet der testedes. Yderligere havde man fire evaluatorer, som hver analyserede testdeltagernes tænkehøjttest. Evaluatorerne rapporterede problemerne og alles rapporter sammenlignedes, hvorefter duplikater blev fratrukket, indtil man kun havde unikke problemstillinger tilbage. Evaluatorne lavede en top 10-liste, over de problemer de fandt mest kritiske. Det viste sig, at de ikke alle kom frem til samme resultater. Mens én evaluator kun fandt 46\% af problemerne, så blev kun 20\% af de samlede problemer fundet af alle fire evaluatorer. Hvad angår top 10-listerne, var der blandt andet ikke ét problem der optrådte på alles liste. Evaluatoreffekten er derfor en faktor der skal medregnes, når vi kigger på usabilitytest.\\

\noindent Et meget centralt begreb i artiklen er UPT - unique problem token. Alle UPT'er beskriver hver især et unikt problem fundet af evaluatorerne ved en usabilitytest. I artiklen skrives det eksempelvis at der i deres test i alt blev fundet 276 problemer ud fra deres ni opstillede kriterier. Nogle af disse viste sig dog at være duplikater, og da vi kun er interesserede i unikke problemer kortedes dette ned til 93. Fra vores egen usabilitytest kan vi eksempelvis fremhæve problemer vedrørende det røde flammeikon, der hos GroupRoom opstår når der er sket noget nyt, hvilket mange af vores testdeltagere ikke forstod. Derudover gør GroupRoom ikke brugeren tilstrækkeligt opmærksom på at vedkommende skal validere sin konto over den oplyste mail. En opgave det viste sig at alle vores testdeltagere enten havde problemer med.\\

\noindent Table 2 og figure 2 stemmer de nogenlunde overens. Rent visuelt kan vi også se, at figure 2 tilnærmelsesvis viser at 20\% af UPT'erne var fundet af alle evaluatorer, som table 2 dikterer skulle ske. I samme stil passer resten også i deres kategori - 13\% af alle UPT'er blev fundet af præcis 3 evaluatorer, mens 20\% også passer fint til dem der kun blev fundet af 2 evaluatorer. Slutteligt skulle den sidste strimmel med kun enlige observationer denne ca. 46\% af alle UPT'erne - hvilket også må siges at være tilfældet.\\

\noindent Vi fokuserer på formlen på artiklens anden side, og bruger denne til at udregne antallet af UPT'er. I en test med fire deltagere og fire evaluatorer vil der således være \\ 
$19.35 \cdot 4^{0.505} \cdot 4^{0.661} = 97,427$ UPT'er. Da vi finder det svært at have en halv UPT, må der herfor skulle rundes op til 98.\\

\noindent Artiklen kan fint relateres til vores egne erfaringer i usabilitytesten. Vi er ad flere gange støt på situationer, hvor vi internt i gruppen ikke kunne blive enige om graden af 

\noindent Jo flere evaluatorer, des flere UPT'er finder man, men effekten synes, som de også nævner i artiklen, at være stavnerende efterhånden som antallet af evaluatorer går op. Derfor er det i enhver usabilitytests interesse at finde en gylden middelvej for antallet af evaluatorer, da for mange synes at være spild af ressourcer - mens ved kun én evaluator, ifølge undersøgelsen berørt i artiklen, opdages kun 46\% af det samlede antal UPT'er.\\

\noindent Da flere evaluatorer også har en tendens til at finde forskellige problemer, og de er oftest uenige i deres prioritering af eksempelvis top 10-lister over største problemer, som det ses i forsøget i artiklen. Derudover skete det i kun 20\% af gangene, at alle fire evaluatorer fandt det samme problem. Det vil sige, at 80\% af alle fundne problemer, var der mindst en evaluator der anså det for ikke at være et. Dette er naturligvis problematisk, og vi ønsker denne evaluatoreffekt mindsket. Dette kan vi tilgå på flere måder, for eksempel kunne en klarere definition på graden af problemer ville kunne give en mere objektiv analytisk fase af usabilitytests. Et andet bud, kunne være hvis evaluatorerne ikke har set produktet de tjekker før. Ved dette undgår vi, at evaluatorer har dannet sig et indtryk og dermeden holdning af et produkt før de analyserer testdeltagerne. Ultimativt ville det give alle evaluatorer mere enslignende forudsætninger for at analysere en test og man undgår således, at de underbevidst har dannet problemrapporter på forhånd. Det ville dog kræve en testleder der på forhånd havde gennemgået systemet, til at styre testdeltagerne igennem usabilitytesten.\\

\noindent Det der primært overraskede os mest, var det faktum, at fire mennesker med markant viden, ikke kunne finde frem til en prioriteringsliste der var nogenlunde enslignende. At måderne at tilgå og analyserer en usabilitytest kan resultere i så forskellige resultater og så stor spredning af UPT'er.\\


\end{document}
